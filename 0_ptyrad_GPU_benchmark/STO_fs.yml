# STO

init_params : {
    # Experimental params
    'probe_illum_type'       : 'electron', # type: str. Choose between 'electron' or 'xray'
    'probe_kv'               : 300, # type: float, unit: kV. Acceleration voltage for relativistic electron wavelength calculation
    'probe_conv_angle'       : 26.5, # type: float, unit: mrad. Semi-convergence angle for probe-forming aperture
    'probe_defocus'          : -200, # type: float, unit: Ang. Defocus (-C1) aberration coefficient for the probe. Positive defocus here refers to actual underfocus or weaker lens strength following Kirkland/abtem/ptychoshelves convention
    'probe_c3'               : 0, # type: float, unit: Ang. 3rd-order spherical aberration coefficient (C3) for the simulated probe
    'probe_c5'               : 0, # type: float, unit: Ang. 5th-order spherical aberration coefficient (C5) for the simulated probe
    'meas_Npix'              : 128, # type: integer, unit: px (k-space). Detector pixel number, EMPAD is 128. Only supports square detector for simplicity
    'pos_N_scans'            : 16384, # type: int, unit: #. Number of probe positions (or equivalently diffraction patterns since 1 DP / position)
    'pos_N_scan_slow'        : 128, # type: int, unit: #. Number of scan position along slow scan direction. Usually it's the vertical direction of acquisition GUI
    'pos_N_scan_fast'        : 128, # type: int, unit: #. Number of scan position along fast scan direction. Usually it's the horizontal direction of acquisition GUI
    'pos_scan_step_size'     : 0.383359375, # type: float, unit: Ang. Step size between probe positions in a rectangular raster scan pattern
    'meas_calibration'       : {'mode': 'RBF', 'value': 41.20813397}, # {'mode': 'dx', 'value': 0.1494}, # type: dict. 'mode' can be 'dx', 'dk', 'kMax', 'da', 'angleMax', 'n_alpha', 'RBF', and 'fitRBF'. All modes requires a scalar 'value' input except 'fitRBF'. The units are Ang, 1/Ang and mrad for electron.
    # Model complexity
    'probe_pmode_max'        : 10, # type: int, unit: #. Maximum number of mixed probe modes. Set to pmode_max = 1 for single probe state, pmode_max > 1 for mixed-state probe during initialization. For simulated initial probe, it'll be generated with the specified number of probe modes. For loaded probe, the pmode dimension would be capped at this number
    'probe_pmode_init_pows'  : [0.02], # type: list of 1 or a few (pmode_max) floats. Initial power for each additional probe modes. If set at [0.02], all additional probe modes would contain 2% of the total intensity. sum(pmode_init_pows) must be 1 if more than len(pmode_init_pows) > 1. See 'utils.make_mixed_probe' for more details
    'obj_omode_max'          : 1, # type: int, unit: #. Maximum number of mixed object modes. Set to omode_max = 1 for single object state, omode_max > 1 for mixed-state object during initialization. For simulated initial object, it'll be generated with the specified number of object modes. For loaded object, the omode dimension would be capped at this number
    'obj_omode_init_occu'    : {'occu_type': 'uniform', 'init_occu': null}, # type: dict. Occupancy type and value for mixed-object modes. Typically we do 'uniform' for frozen phonon like configurations as {'occu_type': 'uniform', 'init_occu': null}. 'occu_type' can be either 'uniform' or 'custom', if 'custom', pass in the desired occupancy as an array to 'init_occu'
    'obj_Nlayer'             : 23, # type: int, unit: #. Number of slices for multislice object
    'obj_slice_thickness'    : 10, # type: float, unit: Ang. Slice thickness (propagation distance) for multislice ptychography. Typical values are between 1 to 20 Ang
    # Preprocessing
    'meas_permute'           : null, # type: null or list of ints. This applies additional permutation (reorder axes) for the initialized diffraction patterns. The syntax is the same as np.transpose()
    'meas_reshape'           : null, # type: null or list of 3 ints. This applies additional reshaping (rearrange elements) for the initialized diffraction patterns. The syntax is the same as np.reshape(). This is commonly needed to convert the 4D diffraction dataset (Ry,Rx,ky,kx) into 3D (N_scans,ky,kx)
    'meas_flipT'             : [1,1,1], # type: null or list of 3 binary booleans (0 or 1) as [flipup, fliplr, transpose] just like PtychoShleves. Default is null or [0,0,0] but you may need to find the correct flip and transpose to match your dataset configuration. This applies additional flip and transpose to initialized diffraction patterns. It's suggested to use 'meas_flipT' to correct the dataset orientation and this is the only orientaiton-related value attached to output reconstruction folder name
    'meas_crop'              : [null,null,null,null], # type: null or (4,2) nested list of ints as [[scan_slow_start, scan_slow_end], [scan_fast_start, scan_fast_end], [ky_start, ky_end], [kx_start, kx_end]]. If you want to keep some of the dimensions, for example, do [[0,64],[0,64], null, null] to crop in real space but leaves the k-space untouched. This applies additional cropping to the 4D dataset in both real and k-space. This is useful for reconstrucing a subset of real-space probe positions, or to crop the kMax of diffraction patterns. The syntax follows conventional numpy indexing so the upper bound is not included
    'meas_pad'               : {'mode': 'on_the_fly', 'padding_type': 'power', 'target_Npix': 192,'value': 0}, # type: dict. 'mode' can be 'on_the_fly', 'precompute', or null (will disable padding). 'padding_type' can be 'constant', 'edge', 'linear_ramp', 'exp', or 'power'. This will pad the CBED to side length = 'target_Npix' based on the padding_type. If using 'exp' or 'power', the mean diffraction pattern amplitude is used to fit the functional coefficients. 'precompute' will pad the measurements during initialization, while 'on_the_fly' will only pad the measurements during optimization, so it's more efficient for GPU memory. 'on_the_fly' padding doesn't really affect the reconstruction time so it's suggested to always use 'on_the_fly' if you're padding to save the GPU memory.
    'meas_resample'          : {'mode': null, 'scale_factors': [2,2]}, # type: dict. 'mode' can be 'on_the_fly', 'precompute', or null. 'scale_factor' takes a list of 2 floats as [ky_zoom, kx_zoom] that must be the same. This applies additional resampling of initialized diffraction patterns along ky and kx directions. This is useful for changing the k-space sampling of diffraction patterns. See scipy.ndimage.zoom for more details. 'precompute' will resample the measurements during initialization, while 'on_the_fly' will only resample the measurements during optimization, so it's more efficient for GPU memory if you're upsampling (i.e., scale_factor > 1). For downsampling, it's much better to do 'precompute' to save GPU memory. 'on_the_fly' resampling doesn't really affect the reconstruction time so it's suggested to always use 'on_the_fly' if you're upsampling.
    'meas_add_source_size'   : null, # type: null or float, unit: Ang. This adds additional spatial partial coherence to diffraction patterns by applying Gaussian blur along scan directions. The provided value is used as the std (sigma) for the Gaussian blurring kernel in real space. Note that FWHM ~ 2.355 std, so a std of 0.34 Ang is equivalent to a source size (FWHM) of 0.8 Ang
    'meas_add_detector_blur' : null, # type: null or float, unit: px (k-space). This adds additional detector blur to diffraction patterns to emulate the PSF on detector. The provided value is used as the std (sigma) for the Gaussian blurring kernel in k-space. Note that this is applied to the "measured", or "ground truth" diffraction pattern and is different from 'model_params['detector_blur_std']' that applies to the forward simulated diffraction pattern
    'meas_remove_neg_values' : {'mode': 'clip_neg', 'value': null}, # type: dict. Choose the preprocessing method for handling negative values in the measurements. Available options are 'subtract_min', 'subtract_value', 'clip_neg', and 'clip_value'. Previously (before beta3.1) the PtyRAD default is 'subtract_min', while for low dose data is recommended to use 'clip_neg' or 'clip_value' i.e. {'mode': 'clip_neg', 'value': 20}. Current default is 'clip_neg'.
    'meas_add_poisson_noise' : null, # type: null or dict, i.e., {'unit': 'total_e_per_pattern', 'value': 10000} or {'unit': 'e_per_Ang2', 'value': 10000}. This applies additional Poisson noise to diffraction patterns to emulate the Poisson statistics of electron dose based on the given unit, value, and scan step size. This is useful when you have a noise-free simulated dataset and want to try ptychographic reconstruciton at different dose conditions
    'meas_export'            : null, # type: null, boolean, or dict, i.e., {'file_dir': null, 'file_name': 'ptyrad_init_meas', 'file_format': 'hdf5', 'output_shape': null, 'append_shape': true}. Set this to True or a dict to enable exporting the final initialized measurements array to disk for further processing, analysis, or visualization. The exported data layout has the same Python convention with py4DGUI so there's no need to worry about orientation mismatch. This can be used to interactively check whether the meas_flipT is correct. By default the output layout is (N_scans, Ky, Kx), and dropping it to py4DGUI then reshape it into (Ny, Nx, Ky, Kx) keeps the correct orientation. 'file_dir' sets the output directory, if None, it'll export to the same folder as 'meas_params['path']'. 'file_format' supports 'hdf5', 'tif', 'npy', and 'mat'. 'output_shape' takes a list of integers like [Ny, Nx, Ky, Kx] or [N_scans, Ky, Kx]. 'append_shape' is a boolean, if True, it'll append the shape of the array to the output file name.
    'probe_permute'          : null, # type: null or list of int. This applies additional permutation (reorder axes) for the initialized probe. The syntax is the same as np.transpose()
    'pos_scan_flipT'         : null, # type: null or list of 3 binary booleans (0 or 1) as [flipup, fliplr, transpose] just like PtychoShleves. Default value is null or equivalently [0,0,0]. This applies additional flip and transpose to initialized scan patterns. Note that modifing 'scan_flipT' would change the image orientation, so it's recommended to set this to null, and only use 'meas_flipT' to get the orientation correct
    'pos_scan_affine'        : [1,0,85,0], # type: null or list of 4 floats as [scale, asymmetry, rotation, shear] just like PtychoShleves. Default is null or equivalently [1,0,0,0], rotation and shear are in unit of degree. This applies additional affine transformation to initialized scan patterns to correct sample drift and imperfect scan coils
    'pos_scan_rand_std'      : 0.15, # type: null or float, unit: px (real space). Randomize the initial guess of scan positions with Gaussian distributed displacement (std in px) to reduce raster grid pathology
    # Input source and params
    'meas_source'            : 'file', # type: str. Data type of the measurements (diffraction patterns). Currently supporting 'file' or 'custom'. 
    'meas_params'            : {'path': 'data/STO/scan_x128_y128.raw'}, # type: dict, or numpy array. For file type of 'mat', or 'hdf5', it's preferred to provide both the 'path' and 'key' in a dict {'path': <PATH_TO_DATA>, 'key': <DATA_KEY>} to retrieve the data matrix, although PtyRAD would try to retrive the data even without a key. 'tif' would only need the {'path':<PATH_TO_DATA>}. For 'raw' you can optionally pass in 'shape':(N,height,width), 'offset':int, 'gap':int to load the .raw files from EMPAD1 and pre-processed EMPAD datasets. For example, {'path': <PATH_TO_DATA>, 'offset':0, 'gap':0} can be used to load pre-processed EMPAD2 raw dataset with no gap between binary diffraction patterns. The 'shape' will be automatically filled in from 'exp_params', while 'offset':0, and 'gap':1024 are default values for EMPAD1 datasets. For py4dstem processed diffraction patterns (hdf5), use '/datacube_root/datacube/data' for your 'key'. For 'custom' source, pass the numpy array to the 'measurements_params' entry after you load this .yml as a dict
    'probe_source'           : 'simu', # type: str. Data source of the probe. Currently supporting 'simu', 'PtyRAD', 'PtyShv', 'py4DSTEM', and 'custom'
    'probe_params'           : null, # type: null, dict, str, or numpy array. Parameters of the probe loading/initialization. For 'simu' (simulating probe), provide a dict of 'probe_simu_params' to specify the simulation parameters (see 'utils/make_stem_probe' for more details) or null to use only basic paramaters like kV, conv_angle, defocus and c3. For loading probe from 'PtyRAD' or 'PtyShv', provide a str of <PATH_TO_RECONSTRUCTION_FILE>. For 'custom' probe source, pass the 3D numpy array to the 'probe_params' entry after you load this .yml as a dict
    'pos_source'             : 'simu', # type: str. Data source of the probe positions. Currently supporting 'simu', 'PtyRAD', 'PtyShv', 'py4DSTEM', 'foldslice_hdf5', and 'custom'
    'pos_params'             : null, # type: null, str, or numpy array. Parameters of the probe positions loading/initialization. For 'simu' (simulating probe positions), provide null and check whether you need 'scan_flipT'. The positions would be simulated based on 'N_scan_slow', 'N_scan_fast', 'scan_step_size', and 'scan_affine'. For loading probe positions from 'PtyRAD' or 'PtyShv', provide a str of <PATH_TO_RECONSTRUCTION_FILE>. For loading probe positions from 'foldslice_hdf5', provide a str of <PATH_TO_POSITION_FILE>. These hdf5 files are generated from many APS instruments that were previously handled in `fold_slice` using 'p.src_positions='hdf5_pos'. For 'custom' probe position source, pass the (N_scans,2) numpy array to the 'pos_params' entry after you load this .yml as a dict
    'obj_source'             : 'simu', # type: str. Data source of the object. Currently supporting 'simu', 'PtyRAD', 'PtyShv', 'py4DSTEM', and 'custom'
    'obj_params'             : null, # type: null, list of 4 ints, str, or numpy array. Parameters of the object loading/initialization. For 'simu' (simulating object), provide a list of 4 ints (omode, Nz, Ny, Nx) to specify the object shape or null to let PtyRAD determine it (null is suggested and is consistent with how PtyShv creates their initial object). For loading object from 'PtyRAD' or 'PtyShv', provide a str of <PATH_TO_RECONSTRUCTION_FILE>. For 'custom' object source, pass the 4D numpy array to the 'obj_params' entry after you load this .yml as a dict
    'tilt_source'            : 'simu', # type: str. Data source of the object tilts. Currently supporting 'simu', 'PtyRAD', and 'custom'
    'tilt_params'            : {'tilt_type':'all', 'init_tilts':[[0,0]]}, # type: dict, str, or numpy array. Parameters of the object tilt loading/initialization. The object tilt is implemeted by tilted Fresnel propagator, which should be fairly accurate within 1 degree (17 mrad). For 'simu' (simulating object tilts), provide a dict as {'tilt_type':'all', 'init_tilts':[[tilt_y, tilt_x]]}. tilt_y and tilt_x are floats in unit of mrad, defaults are [[0,0]]. 'tilt_type' can be either 'all' or 'each'. 'tilt_type': 'all' will create a (1,2) tilt array specifying all positions has the same tilt as 'initial_tilts', this is a globally uniform object tilt that can be either fixed, hypertune optimized, or AD-optimized (if learning rate of 'obj_tilts' != 0). 'tilt_type': 'each' will create a (N_scans,2) tilt array that all position starts at the same 'init_tilts', but it can be later individually optimized through AD by setting learning rate of 'obj_tilts' != 0, which allows pos-dependent local object tilt correction. For loading object tilts from 'PtyRAD', provide a str of <PATH_TO_RECONSTRUCTION_FILE>. For 'custom' object tilts source, pass the (N_scans,2) or (1,2) numpy array to the 'tilt_params'. You should always provide an initial tilt guess for tilt correction either through hypertune or estimate with '/scripts/get_local_obj_tilts.ipynb' because optimizing tilts with AD from scratch would be too slow and most likely arrive at barely corrected, slice-shifted object
}

# "hypertune_params" determines the behavior of hypertune (hyperparameter tuning) mode and the range of optimizable parameters
# Hypertune optimizable parameters are specified in 'tune_params', these will override the corresponding values in 'exp_params' but follows the exact same definition and unit. 
# Set 'state' to true to enable hypertuning that parameter. 'min', 'max', and 'step' defines the search space and sampling rate. For example, conv_angle with min:24, max:26, step:0.1 would have a search range between 24 and 26 with 0.1 minimal spacing
# It's a better practice to limit your hypertune optimization with no more than 4 parameters simultaneously, and some hierachical strategy (i.e., optimizing dz first, then scale with rotation, then all 4 scan_affine, lastly object tilts) could be much faster / stable
# For typical dataset with sufficient dose, both conv_angle and defocus can be automatically handled by probe optimization. However for low dose dataset (like 1e2 e-/DP), some hypertune of probe parameters could be necessary
hypertune_params : {
    'if_hypertune'   : false, # type: boolean. Default is false. Set to true to run PtyRAD in hypertune (hyperparameter optimization) mode. This is the main switch for hypertune mode so none of the settings in 'hypertune_params' would take effect if 'if_hypertune' is false.
    'collate_results': true, # type: boolean. Default is true. Set to true to collect results/figs specified under 'recon_params' from each hypertune trial to 'output_dir/<HYPERTUNE_FOLDER>' and name them by error metrics followed by trial parameters. This provides a convenient way to quickly examine the hypertune results inside the hypertune folder under the main output directory 'output_dir'. This is an independent control than 'SAVE_ITERS' and will save by the end of the 'NITER' or when the trial is pruned.
    'append_params'  : true, # type: boolean. Default is true. Set to true to append the hyperparameter name/values to the file names of collated result. If set to false, only the error, trial ID, and iter would be preserved. Set this to false to reduce the length of the output file name. The exact parameter values are stored in the .sqlite3 database file.
    'n_trials'       : 5, # type: int. Number of hypertune trials. Each trial is a separate PtyRAD reconstruction with a set of optimizable parameter values (i.e., a configuration). Note that when the hypertune mode is run in parallel (i.e., multiple jobs on multiple GPU nodes accesing the same database/study), each job will run for 'n_trials' times. So submiting 5 jobs with 'n_trials': 200 will get you a total of 1000 trials in the database/study
    'timeout'        : null, # type: float. Stop "study" after the given number of second(s). Null represents no limit in terms of elapsed time. The study continues to create trials until the number of trials reaches n_trials, timeout period elapses, stop() is called or, a termination signal such as SIGTERM or Ctrl+C is received.
    'sampler_params' : {'name': 'TPESampler', 'configs': {'multivariate': true, 'group': true, 'constant_liar': true}}, # type: dict. Sampler is the optimization algorithm used for hyperparameter tuning. See https://optuna.readthedocs.io/en/stable/reference/samplers/index.html for more details.
    'pruner_params'  : {'name': 'HyperbandPruner', 'configs': {'min_resource': 5, 'reduction_factor': 2}}, # type: null, dict. Pruning is early termination of unpromising trials to save computation budget. Set to False to disable pruning (i.e., no early termination). The recommended prunner is HyperbandPruner, see Optuna document for more details
    'storage_path'   : 'sqlite:///hypertune.sqlite3', # type: str. Path to the SQLite database file (i.e., sotrage) as 'sqlite:///<DATABASE_FILENAME>.sqlite3'. This database file keeps the record of hypertune runs and will be automatically created with new hypertube run. If you're doing distributed (e.g. multiple GPU nodes) hypertune by submitting this params file multiple times, then all the GPU worker would be accessing this database to be aware of each other's progress
    'study_name'     : 'STO', # type: str. Name of the hypertune record (i.e., study). Hypertune of different dataset or different search space (i.e., different optimizable parameters) are encouraged to use different study name or even separate database file
    'error_metric'   : 'loss', # type: str. Either use 'loss' or 'contrast'. The current suggested approach is to use 'loss' for rough optimization, while switch to 'contrast' with loaded reconstructed object/probe/pos to refine remaining hyperparameters. 'contrast' is simply calculated by std(img)/mean(std) to reflect reconstruction quality of the object because 'loss' doesn't correlate that well. Note that `contrast` doesn't necessarily change monotonically with iterations, especially at early iterations so you may want to disable pruning and set NITER carefullly. 
    'tune_params'    : { # See https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial for the syntax to configure the search space ranges and types
        'optimizer'  : {'state': false, 'suggest': 'cat', 'kwargs': {'choices': ["Adam", "AdamW", "RMSprop", 'SGD']}, 'optim_configs': {}},
        'batch_size' : {'state': false, 'suggest': 'int', 'kwargs': {'low': 16, 'high': 512, 'log': true}},
        'plr'        : {'state': false, 'suggest': 'cat', 'kwargs': {'choices': [1.0e-2, 1.0e-4, 1.0e-4]}}, # can only set as (1) step != 1 and log=False or (2) step=None and log=True
        'oalr'       : {'state': false, 'suggest': 'float', 'kwargs': {'low': 1.0e-4, 'high': 1.0e-2, 'step': null, 'log': true}},
        'oplr'       : {'state': false, 'suggest': 'float', 'kwargs': {'low': 1.0e-4, 'high': 1.0e-2, 'step': null, 'log': true}},
        'slr'        : {'state': false, 'suggest': 'float', 'kwargs': {'low': 1.0e-4, 'high': 1.0e-2, 'step': null, 'log': true}},
        'tlr'        : {'state': false, 'suggest': 'float', 'kwargs': {'low': 1.0e-4, 'high': 1.0e-2, 'step': null, 'log': true}},
        'dzlr'       : {'state': false, 'suggest': 'float', 'kwargs': {'low': 1.0e-4, 'high': 1.0e-2, 'step': null, 'log': true}},
        'dx'         : {'state': false, 'suggest': 'float', 'kwargs': {'low': 0.1400, 'high': 0.1600, 'step': null, 'log': false}},
        'pmode_max'  : {'state': false, 'suggest': 'int', 'kwargs': {'low': 1, 'high': 8, 'step': 1, 'log': false}},
        'conv_angle' : {'state': false, 'suggest': 'float', 'kwargs': {'low': 24, 'high': 26, 'step': 1, 'log': false}},
        'defocus'    : {'state': false, 'suggest': 'float', 'kwargs': {'low': -50, 'high': 50, 'step': 0.1, 'log': false}},
        'c3'         : {'state': false, 'suggest': 'float', 'kwargs': {'low': 4000, 'high': 10000, 'step': null, 'log': false}},
        'c5'         : {'state': false, 'suggest': 'float', 'kwargs': {'low': 50000, 'high': 100000, 'step': 5000, 'log': false}},
        'Nlayer'     : {'state': false, 'suggest': 'int', 'kwargs': {'low': 1, 'high': 8, 'step': 1, 'log': false}},
        'dz'         : {'state': false, 'suggest': 'float', 'kwargs': {'low': 4, 'high': 8, 'step': 0.5, 'log': false}},
        'scale'      : {'state': true, 'suggest': 'float', 'kwargs': {'low': 0.8, 'high': 1.2, 'step': 0.02, 'log': false}}, # This modifies the effective scan step size. [scale, asymmetry, rotation, shear] corresponds to 'scan_affine' under 'exp_params'
        'asymmetry'  : {'state': false, 'suggest': 'float', 'kwargs': {'low': -0.2, 'high': 0.2, 'step': 0.05, 'log': false}},
        'rotation'   : {'state': true, 'suggest': 'float', 'kwargs': {'low': -4, 'high': 4, 'step': 0.5, 'log': false}}, # This is essentially scan rotation
        'shear'      : {'state': false, 'suggest': 'float', 'kwargs': {'low': -4, 'high': 4, 'step': 0.5, 'log': false}},
        'tilt_y'     : {'state': false, 'suggest': 'float', 'kwargs': {'low': -5, 'high': 5, 'step': 0.5, 'log': false}}, # This refers to the 'init_tilts' under 'source_params['tilt_params']['init_tilts']'
        'tilt_x'     : {'state': false, 'suggest': 'float', 'kwargs': {'low': -5, 'high': 5, 'step': 0.5, 'log': false}}
    }
}

# "model_params" determines the forward model behavior, the optimizer configuration, and the learning of the PyTorch model (PtychoAD)
# optimizer configurations are specified in 'optimizer_params', see https://pytorch.org/docs/stable/optim.html for detailed information of available optimizers and configs.
# update behaviors of optimizable variables (tensors) are specified in 'update_params'.
# 'start_iter' specifies the iteration at which the variables (tensors) can start being updated by automatic differentiation (AD)
# 'lr' specifies the learning rate for the variables (tensors)
# Usually slower learning rate leads to better convergence/results, but is also updating slower. 
# The variable optimization has 2 steps, (1) calculate gradient and (2) apply update based on learning rate * gradient
# 'start_iter: null' will disable grad calculation and would not update the variable regardless the learning rate through out the whole reconstruction
# 'start_iter: N(int)' would only calculate the grad when iteration >= N, so no grad will be calculated when iteration < N
# Therefore, only the variable with non-zero learning rate would be optimized when iteration > start_iter.
# If you don't want/need to optimize certain parameters, set their start_iter to null AND learning rate to 0 for faster computation. 
# Typical learning rate is 1e-3 to 1e-4.
model_params : {
    'obj_preblur_std'     : null, # type: null or float, unit: px (real space). This applies Gaussian blur to the object before simulating diffraction patterns. Since the gradient would flow to the original "object" before blurring, it's essentially deconvolving the object with a Gaussian kernel of specified std. This sort of deconvolution can generate sharp features, but the usage is not easily justifiable so treat it carefully as a visualization exploration
    'detector_blur_std'   : 1, # type: null or float, unit: px (k-space). This applies Gaussian blur to the forward model simulated diffraction patterns to emulate the PSF of high-energy electrons on detector for experimental data. Typical value is 0-1 px (std) based on the acceleration voltage 
    'optimizer_params'    : {'name': 'Adam', 'configs': {}, 'load_state': null}, # Support all PyTorch optimizer including LBFGS because LBFGS can't set separate learning rates for different tensors. The suggested optimizer is 'Adam' with default configs (null). You can load the previous optimizer state by passing the path of `model.hdf5` to `load_state`, this way you can continue previous reconstruciton smoothly without abrupt gradients. (Because lots of the optimizers are adaptive and have history-dependent learning rate manipulation, so loading the optimizer state is necessary if you want to continue the previous optimization trajectory). However, the optimizer state must be coming from previous reconstructions with the same set of optimization variables with identical size of the dimensions otherwise it won't run.
    'update_params':{
        'obja'            : {'start_iter': 1, 'lr': 5.0e-4}, # object amplitude
        'objp'            : {'start_iter': 1, 'lr': 5.0e-4}, # object phase
        'obj_tilts'       : {'start_iter': null, 'lr': 0}, # object tilts
        'slice_thickness' : {'start_iter': null, 'lr': 0}, # object dz slice thickness 
        'probe'           : {'start_iter': 1, 'lr': 1.0e-4},  # probe
        'probe_pos_shifts': {'start_iter': 1, 'lr': 5.0e-4}, # sub-px probe positions
    }
}

# "loss_params" determines the individual loss terms for the CombinedLoss used for PtyRAD reconstruction
# Generally, the reconstruction loss is the CombinedLoss = weight1 * loss1 + weight2 * loss2 + weight3 * loss3 ...
# Use 'state' to switch on/off each loss term, and use 'weight' to determine their relative importance. 
# Each loss term would generate their corresponding gradient to the variable, and the final update is determined by the weighted sum of all gradients coming from all participating loss terms. 
# Data-error related loss terms ('loss_single', 'loss_poissn', and 'loss_pacbed') compare simulated DP with experimental DP, and their 'dp_pow' would raise the diffraction pattern to a power before the calculation
# For ptychography purpose, you MUST have at least 1 out of the 3 data-error loss terms. Although you can set all of them to true, typical dataset works fine with 'loss_single' alone
# Soft constraint (regularization)-like loss terms ('loss_sparse', and 'loss_simlar') are optional addition to the required data-error loss terms
# Common regularization terms for image reconstruction tasks are total variation (TV) for smoothness and L_n norm (L1 and L2) for sparsity (i.e., promote near-zero or zero in the reconstructed tensor)
loss_params : {
    'loss_single': {'state': true, 'weight': 1.0, 'dp_pow': 0.5}, # NRMSE error between single simulated and experimental diffraction pattern. 'dp_pow' is commonly set at 0.5 so NRMSE(DP_sim^0.5 - DP_exp^0.5) is equivalent to the Gaussian noise model for typical dataset (dose-sufficient) under the maximum-likelihood formalism
    'loss_poissn': {'state': false, 'weight': 1.0, 'dp_pow': 1.0, 'eps': 1.0e-6}, # negative log likelihood between simulated and experimental diffraction pattern. 'dp_pow' is commonly set at 1 so - (DP_sim * (DP_exp) - DP_exp) is equivalent to the Poisson noise model for low dose dataset under maximum likelihood formalism. See OdstrË‡cil2018 https://doi.org/10.1364/OE.26.003108 for more details
    'loss_pacbed': {'state': false, 'weight': 0.5, 'dp_pow': 0.2}, # NRMSE error between simulated and experimental position-averaved CBED (PACBED). Similar to 'loss_single', except that it's comparing PACBED with PACBED and mostly focusing on the diffuse background when 'dp_pow' is set at 0.2
    'loss_sparse': {'state': true, 'weight': 0.1, 'ln_order': 1}, # L_n norm regularization calculated for object phase. 'ln_order' means the L_n norm (|a_i^n|^(1/n)) used to regularize object phase ('objp'). Usually 'ln_order' is set at 1 for L1 norm (|a|), this promotes 0 in the objp and enhance the sparsity (i.e. discrete atoms). 'ln_order' = 2 would be equivalent to L2 norm that promotes near-0 values
    'loss_simlar': {'state': false, 'weight': 0.1, 'obj_type': 'both', 'scale_factor': [1,1,1], 'blur_std': 1} # std across omode dimension for obj. This promotes similarity between object modes. 'obj_type' can be either 'amplitude', 'phase', or 'both'. 'scale_factor' as (zoom_z, zoom_y, zoom_x) is used to scale the object before calculating the std, setting 'scale_factor' to [1,0.5,0.5]  is equivalent to downsampling the obj 2x along y and x directions before calculating the std, which should encourage the obj modes to keep lateral atom shifts. Similarly, 'blur_std' applies a 2D (lateral) Gaussian blur kernel with specified std to blur the obj before calculating std along omode dimension
}

# "constraint_params" determines the individual iter-wise constraints for the CombinedConstraint used for PtyRAD reconstruction
# Generally, these constraint functions are applied after each (or a couple) iteration(s) to stabilize the optimization trajectories
# When applied, the target tensor is passed through the constraint function, and the tensor get directly modified by the constraint function
# Set 'freq' to a positive integer to specify how often do we want to apply such constraint. For example, 'freq' = 1 would apply the constraint after every iteration, and setting 'freq' to null would disable that constraint. 
# Most constraints are designed specifically for an optimizable tensor to make sure they're following some arbitrary preference
# In other words, we typically choose the constraints according to our optimizable tensors. 
# For example, we need 'ortho_pmode' if we're optimizing mixed-state probe. Similarly, we need either 'obj_zblur' or 'kz_filter' to stabilize the multislice ptychography reconstruciton along z-direction.
# A common combination of constrains for mixed-state probe multislice ptychography would be 'ortho_pmode', 'fix_probe_int', 'kz_filter', and 'objp_postiv'
constraint_params : {
    'ortho_pmode'   : {'freq': 1}, # Apply a SVD decomposition and orthogonalization of the mixed-state probe similar to the PtychoShelves implementation (except it's vectorized in PtyRAD). Turn this on when optimizing with mixed-state probe
    'probe_mask_k'  : {'freq': null, 'radius': 0.22, 'width': 0.05, 'power_thresh': 0.95}, # Apply a k-space sigmoid (similar to a top-hat) probe mask that cut off spatial frequencies beyond the probe-forming aperture. This prevents the probe from absorbing the object structure in k-space. It might cause high-frequency oscillations in the real-space object if you have strong diffuse background in the diffraction pattern and did not provide mixed-object to properly reproduce it. Recommend setting it to 'null' unless you're pursuing mixed-object with more physical probes. k-radius should be larger than 2*rbf/Npix to avoid cutting out the BF disk. 'radius' and 'width' are used to define the sigmoid funciton in relative unit with kMax. See 'utils/make_sigmoid_mask' for more details. 'power_thresh' is used to specify how far into the pmode should be masked. If 'power_thresh': 0.95, the k-space mask would be applied from strongest probe modes to the one that adds uo to 95% total intensity. This promotes a more physical mixed-probe while keeping a small fraction of probe modes to absorb unexpected errors.
    'fix_probe_int' : {'freq': 1}, # Rescale the probe intensity to make it consistent with the total diffraction pattern intensity (so every probe electron hits on the detector). This is needed to stabilize the object amplitude update because the probe update could potentially change the total intensity. This removes the scaling constant ambiguity between probe and object, and should be applied if you're simultaneously optimizing the probe and object amplitude
    'obj_rblur'     : {'freq': null, 'obj_type': 'both', 'kernel_size': 5, 'std': 0.4}, # Apply a "lateral" 2D Gaussian blur to the object. This removes some high frequency noise in the reconstructed object and make the apperance smoother. 'obj_type' can be either 'amplitude', 'phase', or 'both' with a specified 'std' and 'kernel_size' in unit of real-space px. Ideally kernel size is odd (like 5) and larger than 6std+1 so it decays to 0. This is usually not needed if your dataset contains sufficient dose and the kMax is not insanely high (extremely high kMax would gives very fine dx which makes feature appear sharper and probably more seemingly noisy)
    'obj_zblur'     : {'freq': null, 'obj_type': 'both', 'kernel_size': 5, 'std': 1}, # Apply a "z-direction" 1D Gaussian blur to the object. This is a real-space alternative to the typical kz_filter (or so called missing-wedge regularization that applies Fourier filtering to the object) designed for multislice ptychography. Similar to 'obj_rblur', 'obj_type' can be either 'amplitude', 'phase', or 'both' with a specified 'std' and 'kernel_size' in unit of real-space px. Note that the 'ptycho/engines/GPU_MS/private/regulation_multilayers.m' from PtychoShelves (fold_slice) is a combination of 'obja_thresh', 'kr_filter', and 'kz_filter', so you may want to activate all these constraints altogether in PtyRAD to get the most similar effect 
    'kr_filter'     : {'freq': null, 'obj_type': 'both', 'radius': 0.15, 'width': 0.05}, # Apply a "lateral" Fourier low-pass filtering to the object. This is similar to the band-pass filter in Digital Micrograph that the k-space filter has a sigmoid-like profile, essentially a cut-off spatial frequency. Typically we're reconstucting object all the way to kMax (Nyquist frequency) so there's not much room for us to filter out hence it's recommended to keep this off unless you want to exclude certain spatial frequencies. 'radius' and 'width' are used to define the sigmoid funciton in relative unit with kMax. See 'utils/make_sigmoid_mask' for more details
    'kz_filter'     : {'freq': 1, 'obj_type': 'both', 'beta': 1, 'alpha': 1}, # Apply the arctan kz filter just like the 'regulation_multilayers.m' in PtychoShelves. 'beta' controls the strength of the arctan function and is the same as 'eng. regularize_layers' in PtychoShelves. Typical value of 'beta' ranges from 0 to 1. 'alpha' is the implicit constant controls the lateral Fourier filtering that has similar effect as 'kr_filter', usually set as 1 to be consistent with PtychoShelves. Note that 'kz_filter' is designed to be a PtyRAD equivalence of the 'regulation_multilayers.m' so it also includes the arctan Fourier filer, lateral Fourier filter, and the soft object amplitude thresholding if you set 'obj_type' to 'both'. See 'optimization/kz_filter' for more details. While this 'kz_filter' works very well for most multislice reconstructions of crystals, you might prefer 'obj_zblur' if you have an object that has distinct top and bottom layer like twisted bilayer or tilted systems because 'kz_filter' would introduce intermixing between the top and bottom layer due to the periodic boundary condition of Fourier transform. Another solution to the intermixing is to pad vacuum layers to your object and remove them later, although padding extensive vacuum layers tend to make object phase bleed into the vacuum layers and it's very hard to set the interface
    'complex_ratio' : {'freq': null, 'obj_type': 'both', 'alpha1': 1, 'alpha2': 0}, # Apply a complex constraint between object amplitude and phase based on https://doi.org/10.1016/j.ultramic.2024.114068 and https://doi.org/10.1364/OE.18.001981. This will constrain the amplitude to as A' = exp(-C*phase), C is an estimated (adaptive) positive constant, so the amplitude would look similar to phase and strongest phase shift would correspond to less than 1 amplitude. Default value of phase object is alpha1 = 1, alpha2 = 0. Note that the implementation considers the negative correlation between amplitude and phase for electctron ptychography, hence it's not the exact same formula as in the papers.
    'mirrored_amp'  : {'freq': null, 'relax': 0.1, 'scale': 0.03, 'power': 4}, # Apply a more flexible, ad hoc constraint for constraining amplitude using 1-scale*phase**power, which provide more arbitrary parameters to tune the constrained amplitude based on the phase.
    'obja_thresh'   : {'freq': 1, 'relax': 0, 'thresh': [0.96, 1.04]}, # Apply a thresholding of object amplitude around 1. The threshold is defined by 'thresh' and the value is determined by the min and max. Note that wave amplitude is multiplicative when propagating through multislice object, so even an objective amplitude of 0.95 can become 0.6 after 10 layers. The thresholding can be relaxed by the `relax` param that is a weighted sum betwen the pre-threshold and post-threshold values.
    'objp_postiv'   : {'freq': null, 'relax': 0.5}, # Apply a positivity constraint of the object phase, make it non-negative. This clips the negative values (anything below 0) so the object is visually darker but with stronger constrast, it's suggested to keep it on so that you can interpret, compare, and process your object phase with a simple baseline. Besides, the positivity constraint makes it easier to compare with atomic potential ground truth after correct scaling for the scattering factor. The clipping can be relaxed by the `relax` param that is a weighted sum betwen the pre-threshold and post-threshold values.
    'tilt_smooth'   : {'freq': null, 'std': 2} # Apply a lateral Gaussian blur of the local object tilts in unit of "scan positions". This smoothens the local tilts so that you don't have drastic changes of object tilts between scan positions.
}

# "recon_params" determines the overall reconstruction behavior including iterations, grouping/batching, and saving configurations for both reconstruction and hypertune modes
# The PtyRAD results are organized into folder structures with 2 (reconstruction) or 3 (hypertune) levels not including the 'output/'. 
# The main (1st) output directory is specified by 'output_dir', this is usually separated by material systems or projects, and presumably you'll have multiple reconstructions for this material system / project.
# Each PtyRAD reconstruction would be saved into a "reconstruction folder" that will be automatically generated by PtyRAD if 'SAVE_ITERS' is not null.
# For reconstruction mode, the folder structure might look like 'output/<MATERIALS>/<RECONSTRUCTION>'
# Note that 'recon_dir_affixes', 'prefix_date', 'prefix', and 'postfix' all operates on the reconstruction folder and have no effect if 'SAVE_ITERS' is null because reconstuction folder would not be generated from the first place
# The date, pre- and postfix are automatically connected by '_', and the / behind 'output_dir' will also be automatically generated.
# For hypertune mode, a hypertune folder is automatically inserted as the 2nd level between 'output_dir' and the (optional) resonstruction folders. For example, 'output_dir/<MATERIALS>/<HYPERTUNE>/<RECONSTRUCTION>'. This way the hypertune folders are organized under the <MATERIALS> folder just like other reconstruction folders. Note that in hypertune mode, 'prefix_date', 'prefix', and 'postfix' would be applied (i.e., hijacked) on this hypertune folder and have no effect to the reconstruction folder name. In other words, 'prefix_date', 'prefix', and 'postfix' would always be applied to the folders under 'output_dir' for both reconstruction and hypertune modes.
recon_params: {
    'NITER': 500, # type: int. Total number of reconstruction iterations. 1 iteration means a full pass of all selected diffraction patterns. Usually 20-50 iterations can get 90% of the work done with a proper learning rate between 1e-3 to 1e-4. For faster trials in hypertune mode, set 'NITER' to a smaller number than your typical reconstruction to save time. Usually 10-20 iterations are enough for the hypertune parameters to show their relative performance. 
    'INDICES_MODE': {'mode': 'full', 'subscan_slow': null, 'subscan_fast': null}, # type: dict. Indices mode determines multiple ways to use diffraction patterns at each probe positions for reconstructions. Each probe position (or each diffraction pattern) has a unique index, by selecting a subset of the indices, we can conveniently change the effective reconstruction area ('center') or effective scan step size or real space overlap ('sub'). You may choose 'full' for reconstructing with all probe positions, 'sub' for subsampling by selecting only every few probe positions with the full FOV (i.e., this will increase the effective scan step size and is a good way to test whether we can reduce the real space overlap), or 'center' for only using the center rectangular region in real space with a effectively reduced FOV but full sized object canvas. 'subscan_slow' and 'subscan_fast' determine the number of scan positions chosen for 'sub' and 'center', and have no effect to 'full'. If 'subscan_slow' and 'subscan_fast' are not provided (or null), they'll be set to half of the 'N_scan_slow' and half of the 'N_scan_fast' by default. Typically we can start from 'INDICES_MODE': {'mode': 'sub', 'subscan_slow: null, 'subscan_fast': null} to get an quick idea of the entire object by reconstructing the entire object FOV but using only every other diffraction pattern along fast and slow scan directions (so only 1/4 diffraction patterns are used, hence 4x speedup in the iteration time). Similarly we can use 'center' to keep the effective scan step size, but reconstruct a smaller FOV. Once the 'sub' or 'center' show reasonable results, we can then switch to 'full' to further refine it without starting from scratch because there's no object dimension mismatch between the 'INDICES_MODEs'.
    'BATCH_SIZE': {'size': 32, 'grad_accumulation': 1}, # type: dict. Batch size is the number of diffraction patterns processed simultaneously to get the gradient update. 'size' is the number of diffraction pattern in a sub-batch, and 'grad_accumulation' is how many sub-batches' gradients are accumulated before applying the update. Effective batch size (for 1 update) is batch_size * grad_accumulation. Gradient accumulation is a ML technique that allows people to use large effective batch size by trading the iteration time with memory requirement, so if you can fit the entire batch inside your memory, you should always set 'grad_accumulation': 1 for performance. "Batch size" is commonly used in machine learning community, while it's called "grouping" in PtychoShelves. Batch size has an effect on both convergence speed and final quality, usually smaller batch size leads to better final quality for iterative gradient descent, but smaller batch size would also lead to longer computation time per iteration because the GPU isn't as utilized as large batch sizes (due to less GPU parallelism). On the other hand, large batch size is known to be more robust (noise-resilient) but converges slower. Generally batch size of 32 to 128 is used, although certain algorithms (like ePIE) would prefer a large batch size that is equal to the dataset size for robustness. For extremely large object (or with a lot of object modes), you'll need to reduce batch size to save GPU memory, or use `grad_accumulation` to split a batch into multiple sub-batches for 1 update.
    'GROUP_MODE': 'sparse',  # type: str. Group mode determines the spatial distribution of the selected probe positions within a batch (group), this is similar to the 'MLs' for 'sparse' and 'MLc' for 'compact' in PtychoShelves. Available options are 'random', 'sparse', and 'compact'. Usually 'random' is good enough with small batch sizes and is the suggested option for most cases. 'compact' is believed to provide best final quality, although it's converging much slower. 'sparse' gives the most uniform coverage on the object so converges the fastest, and is also preferred for reconstructions with few scan positions to prevent any locally biased update. However, 'sparse' for 256x256 scan could take more than 10 mins on CPU just to compute the grouping, hence PtychoShelves automatically switches to 'random' for Nscans > 1e3. The grouping in PtyRAD is fixed during optimization, but the order between each group is shuffled for every iteration.
    'SAVE_ITERS': 100, # type: null or int. Number of completed iterations before saving the current reconstruction results (model, probe, object) and summary figures. If 'SAVE_ITERS' is 50, it'll create an output reconstruction folder and save the results and figures into it every 50 iterations. If null, the output reconstruction folder would not be created and no reconstruction results or summary figures would be saved. If 'SAVE_ITERS' > 'NITER', it'll create the output reconstruction folder but no results / figs would be saved. Typically we set 'SAVE_ITERS' to 50 for reconstruction mode with 'NITER' around 200 to 500. For hypertune mode, it's suggested to set 'SAVE_ITERS' to null and set 'collate_results' to true to save the disk space, while also provide an convenient way to check the hypertune performance by the collated results.
    'output_dir': 'output/STO/', # type str. Path and name of the main output directory. Ideally the 'output_dir' keeps a series of reconstruction of the same materials system or project. The PtyRAD results and figs will be saved into a reconstruction-specific folder under 'output_dir'. The 'output_dir' folder will be automatically created if it doesn't exist.
    'recon_dir_affixes': ['constraint', 'loss'], # type: list of strings. This list specifies the optional affixes to the reconstruction folder name. The order of strings has NO effect to the output folder name. Available options are 'optimizer', 'start_iter', 'lr', 'model', 'constraint', 'loss', and 'init'. Note that the reconstruction folder should be distinct for each reconstruction run so the results don't get put into the wrong folder. 'optimizer' would affix the name of the PyTorch optimizer. 'start_iter' would affix the iteration at which optimizable variables start being updated by AD. 'lr' would affix the learning rate information. 'constrain', 'model' would affix the std from 'obj_preblur_std' and 'detector_blur_std' under 'model_params' if they're used. 'loss' would affix the activated loss term and their weights. 'init' would affix the initialization parameters like 'conv_angle', 'defocus', 'scan_affine', 'init_tilts' that could potentially be hypertuned. Note that all the affixes can be applied for both reconstruction and hypertune mode, it's just clearer to include 'init' if you're running hypertune mode that may optimize on some initial parameters.
    'prefix_date': true, # type: boolean. Whether to prefix a date str to the reconstruction folder or not. Set to true to automatically prefix a date str like '20240903_' in front of the reconstruction folder name. Suggested value is true for both reconstruction and hypertune modes. In hypertune mode, the date string would be applied on the hypertune folder instead of the reconsstruction folder. 
    'prefix': '', # type: str. Prefix this string to the reconstruction folder name. Note that "_" will be automatically generated, and the attached str would be after the date str if 'prefix_date' is true. In hypertune mode, the prefix string would be applied on the hypertune folder instead of the reconsstruction folder.  
    'postfix': '', # type: str. Postfix this string to the reconstruction folder name. Note that "_" will be automatically generated. In hypertune mode, the postfix string would be applied on the hypertune folder instead of the reconsstruction folder.  
    'save_result': ['model', 'objp'], # type: list of strings. This list specifies the available results to save every SAVE_ITERS, so it keeps the intermediate progress. Available options are 'model', 'obja', 'objp', 'probe', 'probe_prop', and 'optim_state'. 'model' is a nested dict that later got stored as an hdf5 file. 'model' contains optimizable tensors and metadata so that you can always refine from it and load whatever optimizable tensors (object, probe, positions, tilts) if you want to continue the reconstruction. It's similar to the NiterXXX.mat from PtychoShelves. 'object' and 'probe' output the reconstructed object and probe as '.tif'. If you don't want to save anything, set 'SAVE_ITERS' to null. Suggested setting is to save everything (i.e., ['model', 'obja', 'objp', 'probe']). For hypertune mode, you can set 'collate_results' to true and set 'SAVE_ITERS' to null to disable result saving.
    'result_modes': {'obj_dim': [2, 3, 4], 'FOV': ['crop'], 'bit': ['8']}, # type: dict. This dict specifies which object output is saved by their final dimension ('obj_dim'), whether to save the full or cropped FOV ('FOV') of object, and whether to save the raw or normalized bit depth version of object and probe. A comprehensive (but probably redundant) saving option looks like {'obj_dim': [2,3,4], 'FOV': ['full', 'crop'], 'bit': ['raw', '32', '16', '8']}. 'obj_dim' takes a list of int, the int ranges between 2 to 4, corresponding to 2D to 4D object output. Set 'obj_dim': [2] if you only want the zsum from multislice ptychography. Suggested value is [2,3,4] to save all possible output. 'FOV' takes a list of strings, the available strings are either 'full' or 'crop'. Suggested value is 'crop' so the lateral padded region of object is not saved. 'bit' takes a list of strings, the available strings are 'raw', '32', '16', and '8'. 'raw' is the original value range, while '32' normalizes the value from 0 to 1. '16' and '8' will normalize the value from 0 to 65535 and 255 correspondingly. Defualt is '8' to save only the normalized 8bit result for quick visualization. You can set it to ['raw', '8'] if you want to keep the original float32 bit results with normalized 8bit results. These postprocessing would postfix corresponding labels to the result files.
    'selected_figs': ['loss', 'forward', 'probe_r_amp', 'pos'], # type: list of strings. This list specified the selected figures that will be plotted/saved. The available strings are 'loss', 'forward', 'probe_r_amp', 'probe_k_amp', 'probe_k_phase', 'pos', 'tilt', and 'all'. The suggested value is ['loss', 'forward', 'probe_r_amp', 'probe_k_amp', 'probe_k_phase', 'pos'].
    'copy_params': true, # type: boolean. Set to true if you want to copy the .yml params file to the hypertune folder (hypertune mode) or individual reconstruction folders (reconsturction mode). Suggested value is true for better record keeping, although most information is saved in model.pt and can be loaded by ckpt = torch.load('model.pt'), params = ckpt['params'].
    'if_quiet': false, # type: boolean. Set to true if you want to reduce the amount of printed information during PtyRAD reconstruction. Suggested value is false for more information, but if you're running hypertune mode you should consider setting it to true.
}

# Notes about .yml (YAML) file format
# - For each mapping, leave a space after the :, like <key>: <value> so it can be correctly parsed into Python dict
# - Use null (YAML) for None (Python)
# - Use [] for list and {} for dict, avoid () because they might not be parsed correctly
# - For commenting, leave a space before the #
# - The comment for each entry is provided with type, unit, physical meaning, and suggested usage if applicable.
